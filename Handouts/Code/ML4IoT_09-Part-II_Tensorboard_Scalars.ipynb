{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Scalar Logging\n",
    "\n",
    "Source: https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "\n",
    "In this notebok, we'll see how to use tensorboard to examine simple scalar metrics from different training runs. Let us start by importing the required modules and add the tensorboard extension to jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tb_run = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us download the MNIST handwritten digit recognition dataset and build a simple NN model with the Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(512, activation='relu', name='DenseFirst'),\n",
    "        keras.layers.Dense(10, activation='softmax', name='DenseSecond')\n",
    "      ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The TensorBoard callback\n",
    "\n",
    "Let us use the TensorBoard callback to log training information. Note that we use a run counter variable, so that the following training runs are saved to a different tensorboard directory and can be visualized separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./tb_log/run_{}'.format(tb_run), histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tb_callback])\n",
    "\n",
    "tb_run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start TensorBoard\n",
    "\n",
    "Start TensorBoard directly in the notebook or from the command line (for that, simply remove the initial % from the following command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir tb_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Logging\n",
    "\n",
    "Let's try logging some custom scalars from a custom LR scheduler. Let us define a `file_writer` and use it within the LR scheduling function. We also save to a separate `metrics` sub-directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_writer = tf.summary.create_file_writer('./tb_log/run_{}/metrics'.format(tb_run))\n",
    "\n",
    "def my_lr_schedule(epoch, lr):\n",
    "    lr = lr * 0.8\n",
    "    print('My Schedule:', lr, epoch)\n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('learning_rate', data=lr, step=epoch)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./tb_log/run_{}'.format(tb_run), histogram_freq=1)\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(my_lr_schedule)\n",
    "\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tb_callback, lr_callback])\n",
    "tb_run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go back up to the TensorBoard window to see the new logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
